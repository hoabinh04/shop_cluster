# Feature Engineering cho PhÃ¢n Cá»¥m KhÃ¡ch HÃ ng

## Tá»•ng Quan

Notebook `02_feature_engineering_for_clustering.ipynb` thá»±c hiá»‡n viá»‡c xÃ¢y dá»±ng cÃ¡c biáº¿n thá»ƒ Ä‘áº·c trÆ°ng (feature variants) tá»« luáº­t káº¿t há»£p vÃ  RFM Ä‘á»ƒ phá»¥c vá»¥ cho phÃ¢n cá»¥m khÃ¡ch hÃ ng.

## CÃ¡c Biáº¿n Thá»ƒ Äáº·c TrÆ°ng

### 1. Baseline - Binary Rule Features â­

**MÃ´ táº£**: Äáº·c trÆ°ng nhá»‹ phÃ¢n cÆ¡ báº£n nháº¥t

**CÃ¡ch thá»©c**:
- Má»—i chiá»u (feature) tÆ°Æ¡ng á»©ng vá»›i má»™t luáº­t káº¿t há»£p
- GiÃ¡ trá»‹ = 1 náº¿u khÃ¡ch hÃ ng Ä‘Ã£ mua **táº¥t cáº£** sáº£n pháº©m trong antecedents
- GiÃ¡ trá»‹ = 0 náº¿u khÃ´ng

**CÃ´ng thá»©c**:
```
feature_j(customer_i) = 1 if customer_i bought all items in antecedents(rule_j)
                        0 otherwise
```

**Cáº¥u hÃ¬nh**:
- Weighting: âŒ KhÃ´ng
- RFM: âŒ KhÃ´ng
- Scale Rules: âŒ KhÃ´ng
- Scale RFM: N/A

**Æ¯u Ä‘iá»ƒm**:
- ÄÆ¡n giáº£n, dá»… hiá»ƒu
- TÃ­nh toÃ¡n nhanh
- Baseline Ä‘á»ƒ so sÃ¡nh

**NhÆ°á»£c Ä‘iá»ƒm**:
- KhÃ´ng pháº£n Ã¡nh Ä‘á»™ máº¡nh cá»§a luáº­t
- KhÃ´ng cÃ³ thÃ´ng tin vá» giÃ¡ trá»‹ khÃ¡ch hÃ ng
- Táº¥t cáº£ luáº­t Ä‘Æ°á»£c Ä‘á»‘i xá»­ nhÆ° nhau

---

### 2. Variant A - Weighted Rule Features ğŸ¯

**MÃ´ táº£**: Äáº·c trÆ°ng cÃ³ trá»ng sá»‘ theo Ä‘á»™ máº¡nh cá»§a luáº­t

**CÃ¡ch thá»©c**:
- TÆ°Æ¡ng tá»± binary nhÆ°ng cÃ³ trá»ng sá»‘
- Trá»ng sá»‘ pháº£n Ã¡nh Ä‘á»™ máº¡nh vÃ  tin cáº­y cá»§a luáº­t

**CÃ´ng thá»©c**:
```
weight_j = lift_j Ã— confidence_j

feature_j(customer_i) = weight_j if customer_i bought all items in antecedents(rule_j)
                        0         otherwise
```

**CÃ¡c cÃ´ng thá»©c trá»ng sá»‘ cÃ³ thá»ƒ thá»­**:
1. `lift` (chá»‰ Ä‘á»™ máº¡nh quan há»‡)
2. `lift Ã— confidence` â­ (khuyáº¿n nghá»‹)
3. `lift Ã— support` (quan há»‡ máº¡nh + phá»• biáº¿n)
4. `lift Ã— confidence Ã— support` (tá»•ng há»£p Ä‘áº§y Ä‘á»§)

**Cáº¥u hÃ¬nh**:
- Weighting: âœ… CÃ³ (lift Ã— confidence)
- RFM: âŒ KhÃ´ng
- Scale Rules: âŒ KhÃ´ng (giá»¯ nguyÃªn weighted values)
- Scale RFM: N/A

**Æ¯u Ä‘iá»ƒm**:
- Pháº£n Ã¡nh Ä‘á»™ quan trá»ng cá»§a má»—i luáº­t
- Luáº­t máº¡nh hÆ¡n Ä‘Ã³ng gÃ³p nhiá»u hÆ¡n vÃ o profile khÃ¡ch hÃ ng
- Váº«n giá»¯ tÃ­nh sparse

**NhÆ°á»£c Ä‘iá»ƒm**:
- Phá»©c táº¡p hÆ¡n baseline má»™t chÃºt
- Cáº§n chá»n cÃ´ng thá»©c weighting phÃ¹ há»£p

---

### 3. Variant B - Binary Rules + RFM ğŸ’°

**MÃ´ táº£**: Káº¿t há»£p pattern mua hÃ ng vá»›i giÃ¡ trá»‹ khÃ¡ch hÃ ng

**CÃ¡ch thá»©c**:
- GhÃ©p binary rule features vá»›i RFM features
- RFM Ä‘Æ°á»£c chuáº©n hÃ³a (StandardScaler)
- Rule features giá»¯ nguyÃªn (0/1)

**CÃ´ng thá»©c**:
```
RFM features:
  - Recency: sá»‘ ngÃ y ká»ƒ tá»« láº§n mua cuá»‘i
  - Frequency: sá»‘ láº§n mua (sá»‘ InvoiceNo duy nháº¥t)
  - Monetary: tá»•ng giÃ¡ trá»‹ mua hÃ ng

Combined features = [Binary Rules | RFM_scaled]
```

**Cáº¥u hÃ¬nh**:
- Weighting: âŒ KhÃ´ng
- RFM: âœ… CÃ³ (Recency, Frequency, Monetary)
- Scale Rules: âŒ KhÃ´ng (giá»¯ binary 0/1)
- Scale RFM: âœ… CÃ³ (StandardScaler) - **báº¯t buá»™c**

**LÃ½ do scale RFM**:
- Recency, Frequency, Monetary cÃ³ thang Ä‘o khÃ¡c nhau ráº¥t nhiá»u
  - Recency: 1-400 ngÃ y
  - Frequency: 1-200 láº§n
  - Monetary: 100-100000 GBP
- KhÃ´ng scale â†’ RFM sáº½ chiáº¿m Æ°u tháº¿ quÃ¡ má»©c

**Æ¯u Ä‘iá»ƒm**:
- Bá»• sung thÃ´ng tin vá» giÃ¡ trá»‹ khÃ¡ch hÃ ng
- PhÃ¢n biá»‡t khÃ¡ch hÃ ng VIP vs khÃ¡ch hÃ ng thÆ°á»ng
- Tá»•ng há»£p cáº£ behavior pattern vÃ  value

**NhÆ°á»£c Ä‘iá»ƒm**:
- TÄƒng sá»‘ chiá»u (dimension)
- RFM cÃ³ thá»ƒ "Ã¡t" rule features náº¿u khÃ´ng scale cáº©n tháº­n

---

### 4. Variant C - Weighted Rules + RFM ğŸš€

**MÃ´ táº£**: Biáº¿n thá»ƒ tá»•ng há»£p Ä‘áº§y Ä‘á»§ nháº¥t

**CÃ¡ch thá»©c**:
- Káº¿t há»£p weighted rule features vá»›i RFM
- **Cáº£ hai pháº§n Ä‘á»u Ä‘Æ°á»£c chuáº©n hÃ³a**

**CÃ´ng thá»©c**:
```
Weighted Rules: feature_j = lift_j Ã— confidence_j (if satisfied)

Combined features = [Weighted Rules_scaled | RFM_scaled]
```

**Cáº¥u hÃ¬nh**:
- Weighting: âœ… CÃ³ (lift Ã— confidence)
- RFM: âœ… CÃ³
- Scale Rules: âœ… CÃ³ (StandardScaler) - **quan trá»ng**
- Scale RFM: âœ… CÃ³ (StandardScaler)

**LÃ½ do scale weighted rules**:
- Weighted values cÃ³ thá»ƒ ráº¥t lá»›n (lift Ã— confidence cÃ³ thá»ƒ > 20)
- KhÃ´ng scale â†’ weighted rules sáº½ Ã¡t RFM
- Scale giÃºp cÃ¢n báº±ng contribution giá»¯a rules vÃ  RFM

**Æ¯u Ä‘iá»ƒm**:
- Tá»•ng há»£p Ä‘áº§y Ä‘á»§ nháº¥t: Ä‘á»™ máº¡nh luáº­t + giÃ¡ trá»‹ khÃ¡ch hÃ ng
- CÃ¢n báº±ng tá»‘t giá»¯a cÃ¡c loáº¡i features
- Tiá»m nÄƒng cho káº¿t quáº£ tá»‘t nháº¥t

**NhÆ°á»£c Ä‘iá»ƒm**:
- Phá»©c táº¡p nháº¥t
- Cáº§n hiá»ƒu rÃµ vá» scaling

---

## So SÃ¡nh CÃ¡c Biáº¿n Thá»ƒ

| Biáº¿n Thá»ƒ | Weighting | RFM | Scale Rules | Scale RFM | Complexity | Use Case |
|----------|-----------|-----|-------------|-----------|------------|----------|
| Baseline | âŒ | âŒ | âŒ | N/A | â­ | Baseline comparison |
| Variant A | âœ… | âŒ | âŒ | N/A | â­â­ | Focus on rule strength |
| Variant B | âŒ | âœ… | âŒ | âœ… | â­â­â­ | Balance pattern + value |
| Variant C | âœ… | âœ… | âœ… | âœ… | â­â­â­â­ | Most comprehensive |

---

## TÃ­nh NÄƒng NÃ¢ng Cao

### Lá»c Luáº­t Theo Äá»™ DÃ i Antecedent

**Má»¥c Ä‘Ã­ch**: Loáº¡i bá» luáº­t quÃ¡ Ä‘Æ¡n giáº£n

**CÃ¡ch thá»©c**:
```python
MIN_ANTECEDENT_LENGTH = 2  # Chá»‰ giá»¯ luáº­t cÃ³ Ã­t nháº¥t 2 items

rules_filtered = rules[
    rules['antecedent_length'] >= MIN_ANTECEDENT_LENGTH
]
```

**LÃ½ do**:
- Luáº­t cÃ³ antecedent = 1 item quÃ¡ Ä‘Æ¡n giáº£n (A â†’ B)
- Luáº­t cÃ³ antecedent â‰¥ 2 items phá»©c táº¡p hÆ¡n, cÃ³ Ã½ nghÄ©a hÆ¡n
- VÃ­ dá»¥: `{Teacup A, Teacup B} â†’ Teacup C` thÃº vá»‹ hÆ¡n `{Teacup A} â†’ Teacup B`

**Thá»­ nghiá»‡m**:
- MIN_ANTECEDENT_LENGTH = 1: giá»¯ táº¥t cáº£
- MIN_ANTECEDENT_LENGTH = 2: chá»‰ luáº­t phá»©c táº¡p
- So sÃ¡nh cháº¥t lÆ°á»£ng cá»¥m

---

## Quy TrÃ¬nh Feature Engineering

### BÆ°á»›c 1: Chuáº©n Bá»‹ Dá»¯ Liá»‡u

```python
# Load dá»¯ liá»‡u
df_clean = pd.read_csv("data/processed/cleaned_uk_data.csv")
rules = pd.read_csv("data/processed/rules_apriori_top200_selected.csv")

# Táº¡o Customer Ã— Item matrix
customer_item_bool = create_customer_item_matrix(df_clean)

# TÃ­nh RFM
rfm = calculate_rfm(df_clean)
```

### BÆ°á»›c 2: Lá»c Luáº­t (Optional)

```python
# Lá»c theo Ä‘á»™ dÃ i antecedent
MIN_ANTECEDENT_LENGTH = 1  # hoáº·c 2
rules_filtered = rules[
    rules['antecedent_length'] >= MIN_ANTECEDENT_LENGTH
]
```

### BÆ°á»›c 3: Táº¡o Features

```python
# Baseline
features_baseline = create_binary_rule_features(
    customer_item_bool, 
    rules_filtered
)

# Variant A
features_weighted = create_weighted_rule_features(
    customer_item_bool, 
    rules_filtered,
    weight_formula='lift_confidence'
)

# Variant B
features_binary_rfm = combine_rules_and_rfm(
    features_baseline, 
    rfm,
    scale_rules=False,
    scale_rfm=True
)

# Variant C
features_weighted_rfm = combine_rules_and_rfm(
    features_weighted, 
    rfm,
    scale_rules=True,
    scale_rfm=True
)
```

### BÆ°á»›c 4: LÆ°u Features

```python
# LÆ°u tá»«ng biáº¿n thá»ƒ
output_dir = Path("data/features")
features_baseline.to_csv(output_dir / "baseline_binary.csv")
features_weighted.to_csv(output_dir / "variant_a_weighted.csv")
# ...
```

---

## PhÃ¢n TÃ­ch Features

### Thá»‘ng KÃª CÆ¡ Báº£n

```python
# Äá»™ sparse
sparsity = (features == 0).sum() / features.size * 100

# GiÃ¡ trá»‹ trung bÃ¬nh
mean_value = features.mean()

# PhÃ¢n bá»‘
plt.hist(features.values.flatten(), bins=50)
```

### PCA Visualization

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
features_pca = pca.fit_transform(features)

plt.scatter(features_pca[:, 0], features_pca[:, 1])
plt.xlabel(f"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}%)")
plt.ylabel(f"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}%)")
```

---

## Best Practices

### 1. Scaling Strategy

**NguyÃªn táº¯c chung**:
- Binary features (0/1): **KhÃ´ng cáº§n scale**
- Weighted features (giÃ¡ trá»‹ lá»›n): **NÃªn scale** náº¿u káº¿t há»£p vá»›i features khÃ¡c
- RFM: **LuÃ´n scale** (báº¯t buá»™c)

**Khi nÃ o scale**:
- Khi káº¿t há»£p nhiá»u loáº¡i features vá»›i thang Ä‘o khÃ¡c nhau
- Khi sá»­ dá»¥ng thuáº­t toÃ¡n dá»±a trÃªn khoáº£ng cÃ¡ch (K-Means, DBSCAN)
- Khi muá»‘n cÃ¢n báº±ng contribution giá»¯a cÃ¡c feature groups

**Khi nÃ o khÃ´ng scale**:
- Khi chá»‰ dÃ¹ng binary features
- Khi muá»‘n giá»¯ tÃ­nh interpretability
- Khi test baseline

### 2. Weighting Formula Selection

**Lift only**:
- Æ¯u tiÃªn Ä‘á»™ máº¡nh quan há»‡
- KhÃ´ng quan tÃ¢m táº§n suáº¥t

**Lift Ã— Confidence** â­:
- CÃ¢n báº±ng Ä‘á»™ máº¡nh vÃ  Ä‘á»™ tin cáº­y
- Khuyáº¿n nghá»‹ cho háº§u háº¿t trÆ°á»ng há»£p

**Lift Ã— Support**:
- Æ¯u tiÃªn luáº­t phá»• biáº¿n
- TrÃ¡nh overfit vÃ o luáº­t hiáº¿m

**Lift Ã— Confidence Ã— Support**:
- Tá»•ng há»£p Ä‘áº§y Ä‘á»§
- CÃ³ thá»ƒ quÃ¡ conservative

### 3. RFM Integration

**Best practices**:
- LuÃ´n scale RFM (StandardScaler)
- Xem xÃ©t log transform cho Monetary (náº¿u skewed)
- Kiá»ƒm tra correlation giá»¯a R, F, M

**Common mistakes**:
- âŒ KhÃ´ng scale RFM â†’ RFM Ã¡t rule features
- âŒ Scale rules nhÆ°ng khÃ´ng scale RFM â†’ máº¥t cÃ¢n báº±ng
- âŒ DÃ¹ng RFM raw values â†’ dominated by Monetary

---

## VÃ­ Dá»¥ Cá»¥ Thá»ƒ

### Case Study: KhÃ¡ch HÃ ng A

**Profile**:
- ÄÃ£ mua: {Teacup Pink, Teacup Green, Teacup Roses}
- RFM: Recency=10 days, Frequency=15, Monetary=500 GBP

**Rules**:
1. {Teacup Pink, Teacup Green} â†’ Teacup Roses (lift=18, conf=0.7)
2. {Teacup Pink} â†’ Teacup Green (lift=15, conf=0.8)

**Features**:

| Biáº¿n Thá»ƒ | Rule 1 | Rule 2 | RFM_R | RFM_F | RFM_M |
|----------|--------|--------|-------|-------|-------|
| Baseline | 1 | 1 | - | - | - |
| Variant A | 12.6 | 12.0 | - | - | - |
| Variant B | 1 | 1 | -1.2 | 0.8 | 0.5 |
| Variant C | 0.9 | 0.8 | -1.2 | 0.8 | 0.5 |

*GiÃ¡ trá»‹ scaled lÃ  vÃ­ dá»¥ minh há»a*

---

## ÄÃ¡nh GiÃ¡ Cháº¥t LÆ°á»£ng Features

### Metrics

1. **Sparsity**: % features = 0
   - QuÃ¡ sparse (>95%) â†’ features khÃ´ng Ä‘á»§ discriminative
   - QuÃ¡ dense (<50%) â†’ features cÃ³ thá»ƒ khÃ´ng meaningful

2. **Variance**: Äá»™ phÃ¢n tÃ¡n
   - Variance cao â†’ features Ä‘a dáº¡ng
   - Variance tháº¥p â†’ features khÃ´ng phÃ¢n biá»‡t

3. **Separation**: PCA visualization
   - Clusters rÃµ rÃ ng â†’ features tá»‘t
   - Overlapping nhiá»u â†’ features cáº§n cáº£i thiá»‡n

### So SÃ¡nh Giá»¯a CÃ¡c Biáº¿n Thá»ƒ

Sá»­ dá»¥ng clustering metrics (sáº½ lÃ m á»Ÿ notebook tiáº¿p theo):
- Silhouette Score
- Davies-Bouldin Index
- Calinski-Harabasz Score

---

## BÆ°á»›c Tiáº¿p Theo

Sau khi cÃ³ cÃ¡c biáº¿n thá»ƒ features:

1. **Clustering**: Ãp dá»¥ng K-Means trÃªn tá»«ng biáº¿n thá»ƒ
2. **Evaluation**: So sÃ¡nh cháº¥t lÆ°á»£ng cá»¥m
3. **Analysis**: Giáº£i thÃ­ch Ä‘áº·c Ä‘iá»ƒm tá»«ng cá»¥m
4. **Selection**: Chá»n biáº¿n thá»ƒ tá»‘t nháº¥t

Xem notebook: `03_clustering_and_evaluation.ipynb`

---

## Tham Kháº£o

- Agrawal, R., & Srikant, R. (1994). "Fast Algorithms for Mining Association Rules"
- Hughes, A. M. (1994). "Strategic Database Marketing"
- Tan, P. N., et al. (2005). "Introduction to Data Mining" - Chapter 8: Cluster Analysis
